{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed76e968-7d33-413e-988e-bb901cb5bb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\dhrub\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "C:\\Users\\dhrub\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "lr=joblib.load('lr.pkl')\n",
    "vect=joblib.load('vector.pkl')\n",
    "from tqdm import tqdm\n",
    "#print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f24cfbb-0ce5-4059-90b0-47e5a37fa9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealDataSentimentAnalyzer:\n",
    "    def __init__(self, tfidf_vectorizer, lr_model, finbert_model_path=\"ProsusAI/finbert\",ticker='AAPL'):\n",
    "        \"\"\"\n",
    "        Initialize all 3 sentiment analyzers.\n",
    "        \n",
    "        Parameters:\n",
    "        - tfidf_vectorizer: From Week 2\n",
    "        - lr_model: Logistic Regression from Week 2\n",
    "        - finbert_model_path: FinBERT path\n",
    "        \"\"\"\n",
    "        # VADER (Week 1)\n",
    "        self.vader = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # Logistic Regression (Week 2)\n",
    "        self.vectorizer = tfidf_vectorizer\n",
    "        self.lr_model = lr_model\n",
    "        \n",
    "        # FinBERT (Week 3)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(finbert_model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(finbert_model_path)\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "        self.df_news=None\n",
    "        self.ticker=ticker\n",
    "    \n",
    "    def score_headline_vader(self, headline):\n",
    "        \"\"\"Score using VADER.\"\"\"\n",
    "        scores = self.vader.polarity_scores(headline)\n",
    "        # Return compound score (-1 to +1)\n",
    "        return scores['compound']\n",
    "    \n",
    "    def score_headline_lr(self, headline):\n",
    "        \"\"\"Score using Logistic Regression.\"\"\"\n",
    "        features = self.vectorizer.transform([headline])\n",
    "        proba = self.lr_model.predict_proba(features)[0]\n",
    "        # Return probability difference: positive - negative\n",
    "        return proba[2] - proba[0]\n",
    "    \n",
    "    def score_headline_finbert(self, headline):\n",
    "        \"\"\"Score using FinBERT.\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            headline,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=128\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        probs = torch.softmax(outputs.logits, dim=-1)[0]\n",
    "        # Return probability difference: positive - negative\n",
    "        return (probs[2] - probs[0]).item()\n",
    "\n",
    "    def score_all_headlines(self, headlines, batch_size=16):\n",
    "        \"\"\"\n",
    "        Fast sentiment scoring with progress tracking.\n",
    "        \"\"\"\n",
    "        headlines = list(headlines)\n",
    "        total = len(headlines)\n",
    "    \n",
    "        # ---------- VADER (fast) ----------\n",
    "        vader_scores = [\n",
    "            self.vader.polarity_scores(h)['compound']\n",
    "            for h in headlines\n",
    "        ]\n",
    "    \n",
    "        # ---------- Logistic Regression (vectorized) ----------\n",
    "        X = self.vectorizer.transform(headlines)\n",
    "        lr_probas = self.lr_model.predict_proba(X)\n",
    "        lr_scores = lr_probas[:, 2] - lr_probas[:, 0]\n",
    "    \n",
    "        # ---------- FinBERT (batched + progress) ----------\n",
    "        finbert_scores = np.zeros(total)\n",
    "    \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            with tqdm(total=total, desc=\"FinBERT inference\") as pbar:\n",
    "                for i in range(0, total, batch_size):\n",
    "                    batch = headlines[i:i + batch_size]\n",
    "    \n",
    "                    inputs = self.tokenizer(\n",
    "                        batch,\n",
    "                        return_tensors=\"pt\",\n",
    "                        padding=True,\n",
    "                        truncation=True,\n",
    "                        max_length=128\n",
    "                    ).to(self.device)\n",
    "    \n",
    "                    outputs = self.model(**inputs)\n",
    "                    probs = torch.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "                    scores = (probs[:, 2] - probs[:, 0]).cpu().numpy()\n",
    "                    finbert_scores[i:i + len(scores)] = scores\n",
    "    \n",
    "                    # ✅ progress update\n",
    "                    pbar.update(len(scores))\n",
    "    \n",
    "        # ---------- DataFrame ----------\n",
    "        df = pd.DataFrame({\n",
    "            \"headline\": headlines,\n",
    "            \"vader_sentiment\": vader_scores,\n",
    "            \"lr_sentiment\": lr_scores,\n",
    "            \"finbert_sentiment\": finbert_scores\n",
    "        })\n",
    "    \n",
    "        df[\"mean_sentiment\"] = (\n",
    "            df[\"vader_sentiment\"]\n",
    "            + df[\"lr_sentiment\"]\n",
    "            + df[\"finbert_sentiment\"]\n",
    "        ) / 3\n",
    "    \n",
    "        return df\n",
    "\n",
    "    def load_financial_news(self, news_csv_path):\n",
    "        \"\"\"\n",
    "        Load financial news dataset from CSV.\n",
    "        Expected columns: date, headline, (optional) ticker\n",
    "        \"\"\"\n",
    "        print(f\"Loading news data from {news_csv_path}...\")\n",
    "        self.df_news = pd.read_csv(news_csv_path)\n",
    "\n",
    "        # Convert date to datetime, coerce invalid dates to NaT\n",
    "        self.df_news['date'] = pd.to_datetime(\n",
    "            self.df_news['date'],\n",
    "            errors='coerce'\n",
    "        )\n",
    "\n",
    "        # Remove rows with invalid date/time\n",
    "        self.df_news = self.df_news.dropna(subset=['date'])\n",
    "\n",
    "        # Extract date only\n",
    "        self.df_news['date'] = self.df_news['date'].dt.date\n",
    "\n",
    "        # Filter by ticker if column exists\n",
    "        '''if 'ticker' in self.df_news.columns:\n",
    "            self.df_news = self.df_news[self.df_news['ticker'] == self.ticker]'''\n",
    "\n",
    "        self.df_news=self.df_news[['date','title']]\n",
    "\n",
    "        print(f\"Loaded {len(self.df_news)} news articles for {self.ticker}\")\n",
    "        return self.df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9c50f59-8f19-4a4d-ad18-69bfd99da156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading news data from apple_news_data.csv...\n",
      "Loaded 29752 news articles for AAPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FinBERT inference: 100%|█████████████████████████████████████████████████████████| 29752/29752 [19:34<00:00, 25.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                headline  vader_sentiment  \\\n",
      "0      Berkshire Stock Hits Record Even as Company Re...           0.0000   \n",
      "1                          What Is a Stock Market Index?           0.0000   \n",
      "2      Could Investing $1,000 in Apple Make You a Mil...           0.0000   \n",
      "3                           Dow Jones Industrial Average           0.0000   \n",
      "4                             What Is the S&P 500 Index?           0.0000   \n",
      "...                                                  ...              ...   \n",
      "29747  Investor Expectations to Drive Momentum within...           0.0000   \n",
      "29748  BioTelemetry, Inc. Enters Agreement to Provide...           0.4939   \n",
      "29749  Factors of Influence in 2018, Key Indicators a...           0.7579   \n",
      "29750  New Research: Key Drivers of Growth for Micros...           0.3818   \n",
      "29751  Payment Data Systems Announces Apple Pay Suppo...           0.3182   \n",
      "\n",
      "       lr_sentiment  finbert_sentiment  mean_sentiment  \n",
      "0          0.028195          -0.580646       -0.184150  \n",
      "1          0.320458           0.879587        0.400015  \n",
      "2          0.559069           0.853047        0.470705  \n",
      "3          0.613725           0.847139        0.486955  \n",
      "4          0.928147           0.870749        0.599632  \n",
      "...             ...                ...             ...  \n",
      "29747      0.819218          -0.613357        0.068620  \n",
      "29748      0.732879          -0.847980        0.126266  \n",
      "29749      0.820679           0.543941        0.707507  \n",
      "29750      0.795366           0.417069        0.531412  \n",
      "29751      0.877101          -0.348303        0.282333  \n",
      "\n",
      "[29752 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "obj=RealDataSentimentAnalyzer(vect,lr)\n",
    "obj.load_financial_news('apple_news_data.csv')\n",
    "headlines=obj.df_news['title']\n",
    "df=obj.score_all_headlines(headlines)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ff6831-4baf-49ce-a3ea-e48573a09be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   vader_sentiment  lr_sentiment  finbert_sentiment\n",
      "vader_sentiment           1.000000     -0.010022          -0.031852\n",
      "lr_sentiment             -0.010022      1.000000           0.217220\n",
      "finbert_sentiment        -0.031852      0.217220           1.000000\n"
     ]
    }
   ],
   "source": [
    "cols = ['vader_sentiment', 'lr_sentiment', 'finbert_sentiment']\n",
    "corr_matrix = df[cols].corr()\n",
    "\n",
    "print(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aadcbc4-6635-420d-bfac-96970b3ee6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hence in the entire dataset, vader has almost no correlation with lr and finbert. Lr and finbert have a slight correlation\\nwhich can be dut to a very small dataset used for training lr but finbert has been trained on millions of dataset and hence more reliable. Still its \\ngreat to see even then lr has some suitable correlation with finbert even after been trained on a very small dataset'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Hence in the entire dataset, vader has almost no correlation with lr and finbert. Lr and finbert have a slight correlation\n",
    "which can be dut to a very small dataset used for training lr but finbert has been trained on millions of dataset and hence more reliable. Still its \n",
    "great to see even then lr has some suitable correlation with finbert even after been trained on a very small dataset'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa0b90e-e09f-4dd2-b58e-2522b9a67290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
